---
title: MIME 
description: Project page for "Can Vision Language Models Understand Mimed Actions?"
tagline: "Can Vision Language Models Understand Mimed Actions?"
conference: ACL 2025 Findings
paperlink: TBD
repolink: https://github.com/wise-east/mime
datalink: https://mime-understanding.s3.amazonaws.com/index.html
---

<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="https://justin-cho.com/mime"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="/assets/research_page_template/static/images/banner.png"/>
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="/assets/convmod/static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="conversational moderation, moderation, large language model, evaluation, prompting, prompt engineering">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Academic Project Page</title>
  <link rel="icon" type="image/x-icon" href="/assets/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="/assets/research_page_template/static/css/bulma.min.css">
  <link rel="stylesheet" href="/assets/research_page_template/static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="/assets/research_page_template/static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="/assets/research_page_template/static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="/assets/research_page_template/static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="/assets/research_page_template/static/js/fontawesome.all.min.js"></script>
  <script src="/assets/research_page_template/static/js/bulma-carousel.min.js"></script>
  <script src="/assets/research_page_template/static/js/bulma-slider.min.js"></script>
  <script src="/assets/research_page_template/static/js/index.js"></script>
</head>
<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-2 publication-title">
              Can Vision Language Models Understand Mimed Actions?
            </h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://justin-cho.com" target="_blank">Hyundong Justin Cho</a><sup>1</sup>,</span>
            <span class="author-block">
                <a href="https://www.linkedin.com/in/spencer-lin-xr" target="_blank">Spencer Lin</a><sup>2</sup>,
            </span>
            <span class="author-block">
                <a href="https://tejas1995.github.io/" target="_blank">Tejas Srinivasan</a><sup>3</sup>, 
            </span>
            <span class="author-block">
                <a href="https://saxon.me/" target="_blank">Michael Saxon</a><sup>4</sup>,
            </span>     
            <span class="author-block">
                <a href="https://scholar.google.co.kr/citations?user=6_WZd6AAAAAJ&hl=ko" target="_blank">Deuksin Kwon</a><sup>2</sup>, 
            </span>
            <span class="author-block">
                <a href="https://www.linkedin.com/in/natali-chavez-62956027/" target="_blank">Natali T. Chavez</a><sup>5</sup>,
            </span>
            <span class="author-block">
            <a href="https://jonmay.github.io/webpage/" target="_blank">Jonathan May</a><sup>1</sup>
            </span>


                </div>

                <div class="is-size-5 publication-authors">
                <br/>

                <span class="author-block"><sup>1</sup>&nbsp;<img style="max-width: autho; height: 50px;" src="/assets/isi_logo_red_black.png"/></span>
                &nbsp;
                &nbsp;
                &nbsp;
                <span class="author-block"><sup>2</sup>&nbsp;<img style="max-width: auto; height: 50px;" src="/assets/usc_ict.jpeg"/></span>
                <span class="author-block"><sup>3</sup>&nbsp;<img style="max-width: autho; height: 50px;" src="/assets/usc_logo.png"/></span>
                <span class="author-block"><sup>4</sup>&nbsp;<img style="max-width: autho; height: 50px;" src="/assets/ucsb_logo.png"/></span>
                <span class="author-block"><sup>5</sup>&nbsp;<img style="max-width: autho; height: 50px;" src="/assets/aristotle_logo.png"/></span>
                </div>

                <div class="column has-text-centered">
                <div class="publication-links">
                        <!-- Arxiv PDF link -->
                    <!-- <span class="link-block">
                    <a href="{{page.paperlink}}" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                    </a>
                    </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="{{page.repolink}}" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code (TBD) 
                    </span>
                  </a>
                </span>

                <!-- Data link -->
                <span class="link-block">
                  <a href="{{page.datalink}}" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-database"></i>
                  </span>
                  <span>Data
                  </span>
                </a>
              </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="{{page.paperlink}}" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv (TBD)</span>
                  </a>
                </span>

                <!-- <span class="link-block">
                  <a href="https://docs.google.com/presentation/d/165ZwxObkNQYbFNo7lEOA31L9zOC9PZ98n12G2RS5ego/edit?usp=sharing" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span>Slides</span>
                  </a>
                </span> -->

                <!-- <span class="link-block">
                  <a href="/assets/convmod/naacl2024_darma_a0_portrait_updated.pdf" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span>Poster</span>
                  </a>
                </span> -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero teaser">
  <div class="container is-max-desktop">

    <div class="columns is-centered has-text-centered">
      <h4 class="title is-4 ">Evaluating VLM's Understanding of Human Gestures through Mimed Actions: </h4>
    </div>
    <div class="columns is-centered has-text-centered">
      <h4 class="title is-5 ">A Foundational Prerequisite for Nonverbal Communication Understanding</h4>
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
            <div class="hero-body content has-text-justified">
                <p> 
                  Nonverbal communication (NVC) plays an integral role in human language, but studying NVC in general is challenging because of its broad scope and high variance in interpretation among individuals and cultures.
                  However, mime - the theatrical technique of suggesting intent using only gesture, expression, and movement - is a subset of NVC that consists of explicit and embodied actions with much lower human interpretation variance. 
                  We argue that a solid understanding of mimed actions is a crucial prerequisite for vision-language models capable of interpreting and commanding more subtle aspects of NVC. 
                </p>
            </div>
        </div>
    </div>

  </div>
</section>



<section class="hero teaser">
  <div class="container is-max-desktop">

    <div class="columns is-centered has-text-centered">
      <h3 class="title is-4">Mime Identification Multimodal Evaluation (<span style="font-variant: small-caps;">MIME</span>)</h3>
    </div>  

    <div style="display: flex; align-items: flex-start; gap: 20px; margin-bottom: 40px;">
      <div class="hero-body content" style="flex: 0 0 400px;">
          <img style="width: 100%;" src="/assets/mime/intro.png" alt="MIME Overview">
      </div>
      <div style="flex: 1;">
          <div class="hero-body content has-text-justified">
              <p> 
                Hence, we propose Mime Identification Multimodal Evaluation (MIME), a novel video-based question answering benchmark comprising of 86 mimed actions. 
                <br/>
                <br/>
                The figure on the left shows a simplified illustration of a sample in MIME shown with a single frame from a video of a 3D male character miming a basketball shot. 
                We evaluate with both multiple-choice (MC) and free-form short answer (FF) formats, where the former provides a list of options, which in effect supplies contextual information, while the latter requires the model to provide a short answer without such context and is therefore more challenging. 
                <br/>
                <br/>
                <strong>Spoiler alert:</strong> Humans achieve almost perfect accuracy on identifying mimed actions regardless of evaluation format, adversarial perturbations, and the absence of any salient context (e.g., basketball, court, basketball uniform), while VLMs struggle without salient context. 
              </p>
          </div>
      </div>
  </div>
  </div>
</section>

<section class="hero teaser">
    <div class="container is-max-desktop">
  
      <div class="hero-img">
        <img src="/assets/mime/pipeline.png" alt="MIME pipeline">
      </div>


      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
  
          <div class="hero-body content has-text-justified">
            <p>
              
              We illustrate the pipeline for constructing MIME above. 
              <span style="font-family: monospace;">(1)</span> We first collect motion capture data of a mimed action on a Vicon stage. 
              <span style="font-family: monospace;">(2)</span> Then, a 3D character is retargeted to our motion capture data in Blender, a computer graphics software. 
              <span style="font-family: monospace;">(3)</span> Next, we render frames of the animation with a transparent background. 
              <span style="font-family: monospace;">(4)</span> With frames rendered with transparent backgrounds, we can easily overlay them over images of our choice.
            </p>
          </div>
        </div> 
      </div>
  
    </div>
  </section>


  <section class="hero teaser">
    <div class="container is-max-desktop">
  
      <div class="hero-img">
        <img src="/assets/mime/variants.png" alt="MIME variants">
      </div>


      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
  
          <div class="hero-body content has-text-justified">
            <p>
              The main benefit of our setup is that we can flexibly permute different configurations for each action to ablate the robustness of a VLM's understanding of mimed actions. 
              <br/>
              <br/>
              <span style="font-family: monospace;">(a,b,f,g)</span> are examples of the same animation but with changes to the camera angle. Different body parts become occluded depending on the angle. 
              <span style="font-family: monospace;">(c)</span> and <span style="font-family: monospace;">(h)</span>  only change the character from <span style="font-family: monospace;">(a)</span>. 
              <span style="font-family: monospace;">(c)</span> is a female human character while <span style="font-family: monospace;">(h)</span> is an adversarial character <img src="https://abs.twimg.com/emoji/v2/72x72/1f608.png" alt="😈" style="height: 1.2em; vertical-align: middle; margin: 0 0.1em;"> in a sci-fi spacesuit. 
              <span style="font-family: monospace;">(d)</span> and <span style="font-family: monospace;">(i)</span> are variants of <span style="font-family: monospace;">(a)</span> and <span style="font-family: monospace;">(h)</span> respectively with aligned backgrounds (<span style="font-family: monospace;">=background</span>, e.g., basketball court for basketball-related action) while <span style="font-family: monospace;">(e)</span> and <span style="font-family: monospace;">(j)</span> have adversarial backgrounds (<span style="font-family: monospace;">≠background</span>, e.g., living room).
            </p>
          </div>
        </div> 
      </div>
  
    </div>
  </section>
  
  <section class="hero teaser">
    <div class="container is-max-desktop">
  
      <div class="hero-img">
        <img src="/assets/mime/main_results.png" alt="MIME main results">
      </div>


      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
  
          <div class="hero-body content has-text-justified">
            <p>
              We evaluate various open-weight and API-based vision-language models on MIME. 
              We find that humans are robust to all variations, but VLMs drop performance for adversarial perturbations while the performance improves when exposed to signals from the background that are aligned with the action! This motivates the need for increased research for instilling more robust understanding of human gestures in VLMs.
            </p>
          </div>
        </div> 
      </div>
  
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
  
      <div class="columns is-centered has-text-centered">
        <h3 class="title is-5">Check out the paper for more details and other interesting findings!</h3>
      </div>  

      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
  
          <div class="hero-body content has-text-justified">
            <p>
              We share interesting findings on results with attempts to improve on MIME, such as Chain-of-Thought (CoT) prompting, few-shot in-context learning, and fine-tuning! We also analyze the failure modes of CoT to identify why current VLMs fail so miserably on MIME.  
            </p>
          </div>
        </div> 
      </div>



    </div>
  </section>






<!-- Image carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <img src="/assets/research_page_template/static/images/carousel1.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          First image description.
        </h2>
      </div>
      <div class="item">
        <img src="/assets/research_page_template/static/images/carousel2.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Second image description.
        </h2>
      </div>
      <div class="item">
        <img src="/assets/research_page_template/static/images/carousel3.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
         Third image description.
       </h2>
     </div>
     <div class="item">
      <img src="/assets/research_page_template/static/images/carousel4.jpg" alt="MY ALT TEXT 4"/>
      <h2 class="subtitle has-text-centered">
        Fourth image description.
      </h2>
    </div>
  </div>
</div>
</div>
</section> -->
<!-- End image carousel -->




<!-- Youtube video -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container has-text-centered is-centered">
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/AdRvTkctCcI?si=VHIbN_wRc4jIGEK9" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End youtube video -->





<!--Acknowledgement-->
<!-- <section class="section" id="acknowledgement">
  <div class="container is-max-desktop content">
    <h2 class="title">Acknowledgement</h2>
    <p>
      This material is based upon work supported by the Defense Advanced Research Projects Agency (DARPA) under Agreement Nos. HR00112290025 and HR001121C0169. We would like to thank our reviewers for their helpful reviews that were instrumental in strengthening the validity of our evaluation setting for conversational moderation.
    </p>
  </div>
</section> -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
        TBD
<!-- @misc{cho2025tuningfreepersonalizedalignmenttrialerrorexplain,
        title={Tuning-Free Personalized Alignment via Trial-Error-Explain In-Context Learning}, 
        author={Hyundong Cho and Karishma Sharma and Nicolaas Jedema and Leonardo F. R. Ribeiro and Alessandro Moschitti and Ravi Krishnan and Jonathan May},
        year={2025},
        eprint={2502.08972},
        archivePrefix={arXiv},
        primaryClass={cs.CL},
        url={https://arxiv.org/abs/2502.08972}, 
  } -->
</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>


</body>
</html>
