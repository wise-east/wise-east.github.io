---
title: Justin Cho
---
<!DOCTYPE html>
<html lang="en">
<head>
	{%- include head.html -%}
	<link href="https://assets.calendly.com/assets/external/widget.css" rel="stylesheet">
	<script src="https://assets.calendly.com/assets/external/widget.js" type="text/javascript" async></script>
</head>


{%- assign date_format = site.minima.date_format | default: "%b %-d, %Y" -%}
<body>
	<main class="container" id="top">
		<section class="about">
			<div class="portfolio-img-wrapper">
				<a href="/">
					<img class="portfolio-img" src="{{ '/assets/portfolio.png' | relative_url }}" alt="{{ site.plainwhite.name }}">
				</a>
			</div>

			<h1> Justin Cho  </h1>
			<h1> 조현동 </h1>

			<!-- <h1 class="name">{{ site.plainwhite.name }} </h1> -->
			<div class="tagline">{{ site.plainwhite.tagline }}</div>

			<div class="affiliation-wrapper">
				{% for affil in site.plainwhite.affiliations %}
				<div class="affiliation">
					<a target="_blank" href="{{ affil.link}}">{{ affil.name}}</a>
				</div>
				{% endfor %}
			</div>
			<ul class="social">
				<a href="https://github.com/{{ site.plainwhite.social_links.github }}" target="_blank"><li><i class="icon-github-circled"></i></li></a>
				<a href="https://www.linkedin.com/{{ site.plainwhite.social_links.linkedIn }}" target="_blank"><li><i class="icon-linkedin-squared"></i></li></a>
				<a href="https://twitter.com/{{site.plainwhite.social_links.twitter}}" target="_blank"><li><i class="icon-twitter-squared"></i></li></a>
			</ul>
		</section>
		<section class="content">
			<div class="intro">

				<p> <small> <code class="language-plaintext highlighter-rouge">jcho [at] isi [dot] edu</code></small> / <a href="https://scholar.google.com/citations?user=9YrOON8AAAAJ&hl=en" target="_blank">google scholar</a> / <a href="{{ '/assets/cv.pdf' | relative_url }}" target="_blank">resume</a> / <a href="{{ '/blog.html' | absolute_url}}">blog</a></p>
				<div class="intro-text">
					I am a PhD student at the University of Southern California's (USC) Information Sciences Institute (ISI), advised by Prof. <a href="https://www.isi.edu/~jonmay/" target="_blank"> Jonathan May</a>. 
					<br>
					<br> 
					My research interest is in natural language processing (NLP), specifically in natural language generation and dialogue systems. I am interested in making both open-domain and task-oriented dialogue systems more robust and versatile by 1) reducing the distribution shift from training time to deployment, 2) leveraging non-dialogue data to learn better representations about the world, and 3) learning continually and adapt to changes in the world. 
					<br> 
					<br>
					Ultimately, I want to establish chatbots as the main interface that we use to interact with machines. Conversations are the most convenient means of communication for most people and so I believe my goal will make even complex intelligent systems accessible to a wider group of people, regardless of their technical expertise. Think of Samantha in <a href="https://en.wikipedia.org/wiki/Her_(film)"> Her </a> and <a href="https://interstellarfilm.fandom.com/wiki/TARS"> TARS </a> in Interstellar! 
				</div>

				<div class="intro-text">
					Prior to my PhD program, I worked at ISI as a programmer analyst and graduated from HKUST with a Bachelor's in Computer Science. I have interned at <a href="https://ai.facebook.com/research/" target="_blank">Meta AI</a>, <a href="https://www.stitchfix.com/" target="_blank">Stitch Fix</a>, <a href="https://www.isi.edu/research_groups/nlg/home" target="_blank"> ISI's Natural Language Group</a>, and <a href="https://www.imago.ai/" target="_blank"> Imago.ai</a>. 
				</div>
			</div>	

			<div id="office-hours">
				<h3> Office hours</h3>
				<div>
					I am hosting virtual office hours for those who want my advice/thoughts on their topic of interest. My primary intent for these office hours is knowledge transfer, helping you with productivity tips and getting started with research or with CS. 
					<a href="" onclick="Calendly.initPopupWidget({url: 'https://calendly.com/jcho-9/office-hours'});return false;">Please schedule through Calendly.</a> 
					I will do my best to accommodate different time zones.
				</div>
			</div>

			<div id="research">
				<h3> Research </h3>

				<div class="research-item"  style="margin-bottom: 10px;">

					<div class="pull-left thumbnail-wrapper">
						<img src="{{ '/assets/checkdst/checkdst.png' | absolute_url }}" alt="checkdst-thumbnail" class="thumbnail">
					</div>

					<div class="description">
						<div class="paper-title"> 
							<a href="https://arxiv.org/abs/2112.08321" target="_blank"> Know Thy Strengths: Comprehensive Dialogue State Tracking Diagnostics</a>	
						</div>
						<div class="authors">
							<u><strong>Hyundong J. Cho</strong></u>, Chinnadhurai Sankar, Christopher Lin, Kaushik Ram Sadagopan, Shahin Shayandeh, Asli Celikyilmaz, Jonathan May, Ahmad Beirami, <em>EMNLP2022 Findings</em> <a href="https://arxiv.org/abs/2112.08321" target="_blank"> [paper] </a> 
							<a href="{{ '/checkdst' | absolute_url }}"> [project page] </a>
						</div>

						<div class="excerpt">
							We present our findings from standardized and comprehensive DST diagnoses, which have previously been sparse and uncoordinated, using our toolkit, CheckDST, a collection of robustness tests and failure mode analytics. We discover that different classes of DST models have clear strengths and weaknesses, where generation models are more promising for handling language variety while classification models are more robust to unseen entities.
						</div>
					</div>

				</div>

				<div class="research-item">

					<div class="pull-left thumbnail-wrapper">
						<img src="{{ '/assets/reflect_not_reflex.png' | absolute_url }}" alt="reflect-thumbnail" class="thumbnail">
					</div>

					<div class="description">
						<div class="paper-title"> 
							<a href="https://arxiv.org/abs/2211.09267" target="_blank"> Reflect, Not Reflex: Inference-Based Common Ground Improves Dialogue Response Quality</a>	
						</div>
						<div class="authors">
							Pei Zhou, <u><strong>Hyundong J. Cho</strong></u>, Pegah Jandaghi, Dong-Ho Lee, Bill Yuchen Lin, Jay Pujara, Xiang Ren. <em>EMNLP2022 </em> <a href="https://arxiv.org/abs/2211.09267" target="_blank"> [paper] </a> <a href="https://inklab.usc.edu/Reflect/" target="_blank"> [project page]</a>
						</div>

						<div class="excerpt">
							We introduce Reflect, a dataset that annotates dialogues with explicit CG and solicits 9k diverse human-generated responses each following one common ground. Using Reflect, we showcase the limitations of current dialogue data and RG models: less than half of the responses in current data are rated as high quality and models trained using this data have even lower quality, while most Reflect responses are judged high quality. We also analyze whether CG can help models produce better-quality responses by using Reflect CG to guide RG models. </div>
					</div>

				</div>

				<div class="research-item">


					<div class="pull-left thumbnail-wrapper">
						<img src="{{ '/assets/zhou_emnlp2021.png' | absolute_url }}" alt="emnlp2021findings-thumbnail" class="thumbnail">
					</div>

					<div class="description">
						<div class="paper-title"> 
							<a href="https://aclanthology.org/2021.findings-emnlp.349" target="_blank"> Probing Commonsense Explanation in Dialogue Response Generation </a>
						</div>
						<div class="authors">
							Pei Zhou, Pegah Jandaghi, <u><strong>Hyundong J. Cho</strong></u>, Bill Yuchen Lin, Jay Pujara, Xiang Ren. <em>EMNLP2021 Findings</em> <a href="https://aclanthology.org/2021.findings-emnlp.349" target="_blank"> [paper] </a> 
						</div>

						<div class="excerpt">
							We collect 6k annotated explanations justifying responses from four dialogue datasets and ask humans to verify them and propose two probing settings to evaluate response generation models' commonsense reasoning capabilities. Probing results show that response generation models fail to capture the logical relations between commonsense explanations and responses and fine-tuning on in-domain data and increasing model sizes do not lead to understanding of commonsense reasoning. 
						</div>
					</div>

				</div>
				<div class="research-item"> 

					<div class="pull-left thumbnail-wrapper">
						<img src="{{ '/assets/dialdoc2021.png' | absolute_url }}" alt="dialdoc2021-thumbnail" class="thumbnail">
					</div>

					<div class="description">
						<div class="paper-title"> 
							<a href="https://aclanthology.org/2021.dialdoc-1.15/">Agenda Pushing in Non-collaborative Dialogue </a>
						</div>
						<div class="authors">
							<u><strong>Hyundong J. Cho</strong></u>, <a href="https://steel.isi.edu/members/gbartlet/" target="_blank"> Genevieve Bartlett</a>,
							<a href="https://www.isi.edu/people/mrf/about" target="_blank">Marjorie Freedman</a>.  <em>ACL2021 DialDoc Workshop.</em> <a href="https://aclanthology.org/2021.dialdoc-1.15/" target="_blank"> [paper] </a> 
						</div>

						<div class="excerpt">
							We propose <i>Puppeteer</i> as a promising framework to combat social-engineering attacks by automatically responding to emails: a hybrid system that uses customizable probabilistic finite state transducers to orchestrate pushing agendas coupled with neural dialogue systems that generate responses to unexpected prompts. We emphasize the need for this system by highlighting each component's strengths and weaknesses and show how they complement each other.
						</div>
					</div>

				</div>


				<div class="research-item">
					<div class="pull-left thumbnail-wrapper">
						<img src="{{ '/assets/spolin/yesand_example2.png' | absolute_url }}" alt="spolin-thumbnail" class="thumbnail">
					</div>

					<div class="description">
						<div class="paper-title"> 
							<a href="https://aclanthology.org/2020.acl-main.218/"> Grounding Conversations with Improvised Dialogues </a>
						</div>
						<div class="authors">
							<u><strong>Hyundong J. Cho</strong></u>, <a href="https://www.isi.edu/~jonmay/" target="_blank"> Jonathan May</a>. <em>ACL2020.</em>
							<a href="https://aclanthology.org/2020.acl-main.218/" target="_blank"> [paper] </a> 
							<a href="{{ '/spolin' | absolute_url }}"> [project page] </a> 
							<a href="https://spolin.isi.edu" target="_blank"> [demo]</a>
						</div>
						<div class="press">
							Press: 
								<a href="https://www.sciencedaily.com/releases/2020/07/200715095502.htm" target="_blank">Science Daily</a>, 
								<a href="https://viterbischool.usc.edu/news/2020/07/move-over-siri-usc-viterbi-researchers-develop-improv-based-chatbot/">USC Viterbi</a>, 
								<a href="https://www.mindbounce.com/445861/meet-the-chatbot-thats-learning-to-improvise/">mindbounce</a>, 
								<a href="https://techwithgajesh.com/spolinbot-the-new-avatar-of-chatbots/">Tech With Gajesh</a>
						</div>

						<div class="excerpt">
							Open-domain dialogue systems overlook an important phenomena that makes conversations engaging: grounding. We collect "Yes, and" type dialogue pairs from an improv podcast and existing dialogue corpora to create the Spontaneanation Pairs Of Learnable ImprovisatioN (<span class="spolin-text">SPOLIN</span>) dataset. Human evaluation shows that models fine-tuned with <span class="spolin-text">SPOLIN</span> generate more engaging results. 
						</div>
					</div>

				</div>


			</div>

			<div id="research">
				<h3> Preprints / Others </h3>



				<div class="research-item">

					<div class="pull-left thumbnail-wrapper">
						<img src="{{ '/assets/viola.png' | absolute_url }}" alt="viola-thumbnail" class="thumbnail">
					</div>

					<div class="description">
						<div class="paper-title"> 
							<a href="https://arxiv.org/abs/2108.11063" target="_blank"> Viola: A Topic Agnostic Generate-and-Rank Dialogue System  </a>
						</div>
						<div class="authors">
							<u><strong>Hyundong J. Cho</strong></u>, Basel Shbita, Kartik Shenoy, Shuai Liu, Nikhil Patel, Hitesh Pindikanti, Jennifer Lee, Jonathan May. <a target="_blank" href="https://developer.amazon.com/alexaprize/challenges/current-challenge/sgc4-proceedings"> Alexa Prize Socialbot Grand Challenge 4 Proceedings</a>, 2021 
						</div>

						<div class="excerpt">
							We present Viola, an open-domain dialogue system based on a simple generate-and-rank approach. Viola fetches a batch of response candidates from various neural dialogue models and template-based generators and chooses the final response with a poly-encoder ranker fine-tuned with annotated Alexa conversation data. 
						</div>
					</div>
				</div>

			</div>


			<div id="news">
				<h3> News </h3>
				<div>
					<ul>
						<li>
							2022/11: I'll be attending EMNLP 2022 in person to present <a href="https://arxiv.org/abs/2112.08321" target="_blank"> Know Thy Strengths: Comprehensive Dialogue State Tracking Diagnostics</a> and <a href="https://arxiv.org/abs/2211.09267" target="_blank"> Reflect, Not Reflex: Inference-Based Common Ground Improves Dialogue Response Quality</a>. 
						</li>
						<li>
							2022/6: I've started my summer internship at Meta AI to work on continual learning. 
						</li>
						<li>
							2021/8: I started my intership with <a href="https://ai.facebook.com/research/conversational-ai/" target="_blank">Meta AI's Conversational AI</a> team to work on the robustness of task-oriented dialogue models. 
						</li>
						<li>
							2021/8: <em> "Probing Causal Common Sense in Dialogue Response Generation"</em>, work with Pei Zhou, has been accepted to EMNLP2021 Findings. 
						</li>
						<!-- <li>
							2021/5: I will be interning at <a href="https://ai.facebook.com/research/conversational-ai/" target="_blank">Facebook's Conversational AI</a> team for the Fall semester of 2021!
						</li> -->
						<li>
							2021/4: <a href="https://developer.amazon.com/alexaprize/challenges/current-challenge/teams/viola" target="_blank">Viola</a> makes it to the semi-finals of the Alexa Prize Socialbot Grand Challenge 4! 
						</li>						
						<li>
							2020/11: <a href="https://developer.amazon.com/alexaprize/challenges/current-challenge/teams/viola" target="_blank">Viola</a> is one of the teams accepted to compete in the <a href="https://www.amazon.science/latest-news/nine-university-teams-selected-to-compete-in-the-alexa-prize-socialbot-grand-challenge-4" target="_blank">Alexa Prize Socialbot Grand Challenge 4</a>! I will be leading the team with <a href="https://www.isi.edu/~jonmay/" target="_blank">Jonathan May</a> as our faculty advisor. 
						</li>
						<li>
							2020/9: Stitch Fix posted a <a href="https://multithreaded.stitchfix.com/blog/2020/10/20/intern-post/" target="_blank">blog post</a> about my internship project using NLP to process client feedback for its products. Check it out! 
						</li>
						<li>
							2020/9: USC Viterbi Magazine covered <a href="https://www.isi.edu/~jonmay/" target="_blank">Jonathan May</a>'s and my SPOLIN work that was published at ACL2020, with a fun video demonstration featuring <a href="https://www.mikehenry.co/" target="_blank">Mike Henry</a> (Family Guy, The Orville). <a href="https://magazine.viterbi.usc.edu/fall-2020/features/you-are-an-ai-yes-and-i-also-do-improv-comedy/?fbclid=IwAR3hGzvK6C8-95JU8F3xv9F99nOri9BpdAT1MErsDHfsUpRmiI8Brpe38vU" target="_blank">Check it out!</a>
						</li>
						<li>
							2020/8: I am starting my first semester as a PhD student at USC.
						</li>
						<li>
							2020/6: I will be working at <a href="https://www.stitchfix.com/" target="_blank">Stitch Fix</a> as a data science intern in the merch product development team.
						</li>
						<li>
							2020/4: My paper with <a href="https://www.isi.edu/~jonmay/" target="_blank"> Jonathan May</a> has been accepted to ACL2020! I will be presenting virtually at the conference.
						</li>
					</ul>
				</div>
				
			</div>

			<div id="Misc.">
				<h3> Misc. </h3>

				<ul>
					<li>
						My pronouns are he, him, his.
					</li>

					<li>
						I have been very fortunate to have lived in many different countries: Moscow, Russia; Oslo, Norway; Vienna, Austria; Abu Dhabi, UAE; Hong Kong; Tehran, Iran; Seoul, South Korea; Los Angeles, California. I look forward to living in new places and experiencing different cultures.
					</li>

					<li>
						I love playing football⚽ and I am a huge fan of FC Barcelona. Visca el Barça!
					</li>

					<li>
						I am a citizen of South Korea and the US. I am fluent in both English and Korean. I am teaching myself Mandarin with Duolingo and HSK level tests. 我希望能在不远的将来用流利的中文和你交流。
					</li>

				</ul>
			</div>


			
		</section>


	</main>

	<div class="footer">
		Last updated: November 2022. <a href="#top"> Back to top </a>
	</div>


	{%- if site.plainwhite.analytics_id -%}
	<script async src="https://www.googletagmanager.com/gtag/js?id={{ site.plainwhite.analytics_id }}"></script>
	<script>
		window.dataLayer = window.dataLayer || [];
		function gtag() { dataLayer.push(arguments); }
		gtag('js', new Date());

		gtag('config', '{{ site.plainwhite.analytics_id }}');
	</script>
	{%- endif -%}
</body>
</html>


